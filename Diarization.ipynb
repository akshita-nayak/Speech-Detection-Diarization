{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wwPyQTCNlOZ",
        "outputId": "849e8402-52ad-482d-dc49-2cfe45df4e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install typing-extensions==3.7.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEXP1x9FPHLt",
        "outputId": "04dd673e-a003-411f-81e4-1cd861fdcad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting typing-extensions==3.7.4.1\n",
            "  Downloading typing_extensions-3.7.4.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.4.0\n",
            "    Uninstalling typing-extensions-4.4.0:\n",
            "      Successfully uninstalled typing-extensions-4.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydantic 1.10.2 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.1 which is incompatible.\n",
            "arviz 0.12.1 requires typing-extensions>=3.7.4.3, but you have typing-extensions 3.7.4.1 which is incompatible.\u001b[0m\n",
            "Successfully installed typing-extensions-3.7.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q https://github.com/pyannote/pyannote-audio/tarball/develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rz85YKwPQhH",
        "outputId": "b23c2eea-aff2-4255-cb83-cc64f8cdeb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for pyannote.audio (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Voice Activity Detection\n",
        "!pip install webrtcvad\n",
        "import contextlib\n",
        "import numpy as np\n",
        "import wave\n",
        "import librosa\n",
        "import webrtcvad\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AxgsyDcPeU0",
        "outputId": "5f45a102-a88b-44d8-fe1a-d11d5fc2fe83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.8/dist-packages (2.0.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_wave(path):\n",
        "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "        num_channels = wf.getnchannels()\n",
        "        assert num_channels == 1\n",
        "        sample_width = wf.getsampwidth()\n",
        "        assert sample_width == 2\n",
        "        sample_rate = wf.getframerate()\n",
        "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "        pcm_data = wf.readframes(wf.getnframes())\n",
        "        return pcm_data, sample_rate\n",
        "\n",
        "\n",
        "class Frame(object):\n",
        "  def __init__(self, bytes, timestamp, duration):\n",
        "        self.bytes = bytes\n",
        "        self.timestamp = timestamp\n",
        "        self.duration = duration\n",
        "\n",
        "\n",
        "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "    offset = 0\n",
        "    timestamp = 0.0\n",
        "    duration = (float(n) / sample_rate) / 2.0\n",
        "    while offset + n < len(audio):\n",
        "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "        timestamp += duration\n",
        "        offset += n\n",
        "\n",
        "\n",
        "def vad_collector(vad, frames, sample_rate):\n",
        "    is_speech = []\n",
        "    for frame in frames:\n",
        "        is_speech.append(vad.is_speech(frame.bytes, sample_rate))\n",
        "    return is_speech\n",
        "\n",
        "\n",
        "def vad(file):\n",
        "    audio, sample_rate = read_wave(file)\n",
        "    vad = webrtcvad.Vad(2)\n",
        "    frames = frame_generator(10, audio, sample_rate)\n",
        "    frames = list(frames)\n",
        "    segments = vad_collector(vad, frames, sample_rate)\n",
        "    return segments\n",
        "\n",
        "def speech(file):\n",
        "  dummy = 0\n",
        "  data = []\n",
        "  segments = vad(file)\n",
        "  audio, sr = librosa.load(file)\n",
        "  for i in segments:\n",
        "    if i == True:\n",
        "      data.append(audio[dummy:dummy + 480])\n",
        "      dummy = dummy + 480\n",
        "    else:\n",
        "      dummy = dummy + 480\n",
        "  data = np.ravel(np.asarray(data))\n",
        "\n",
        "  return data\n",
        "\n",
        "def fxn(file):\n",
        "  segments = vad(file)\n",
        "  segments = np.asarray(segments)\n",
        "  dummy = 0.01*np.where(segments[:-1] != segments[1:])[0] +.01 \n",
        "  if len(dummy)%2==0:\n",
        "    dummy = dummy\n",
        "  else:\n",
        "    dummy = np.delete(dummy, len(dummy)-1)\n",
        "\n",
        "  voice = dummy.reshape(int(len(dummy)/2),2)\n",
        "  \n",
        "  return voice"
      ],
      "metadata": {
        "id": "gczEoRfgPk3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Segmentation (Each Segment will have only one Speaker)\n",
        "%tensorflow_version 2.x\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, TimeDistributed, Dropout\n",
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(32)))\n",
        "model.add(TimeDistributed(Dense(32)))\n",
        "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "\n",
        "model.build(input_shape=(None, 137, 35))\n",
        "model.summary()\n",
        "#Upload the pre-trained model file from Google Drive. Change the Path accordingly.\n",
        "h5_model_file = '/content/drive/My Drive/ProjectContent/model_hindi_2.h5'\n",
        "model.load_weights(h5_model_file)\n",
        "\n",
        "\n",
        "def multi_segmentation(file):\n",
        "    frame_size = 2048\n",
        "    frame_shift = 512\n",
        "    y, sr = librosa.load(file)\n",
        "    mfccs = librosa.feature.mfcc(y, sr, n_mfcc=12, hop_length=frame_shift, n_fft=frame_size)\n",
        "    mfcc_delta = librosa.feature.delta(mfccs)\n",
        "    mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
        "\n",
        "    mfcc = mfccs[1:, ]\n",
        "    norm_mfcc = (mfcc - np.mean(mfcc, axis=1, keepdims=True)) / np.std(mfcc, axis=1, keepdims=True)\n",
        "    norm_mfcc_delta = (mfcc_delta - np.mean(mfcc_delta, axis=1, keepdims=True)) / np.std(mfcc_delta, axis=1, keepdims=True)\n",
        "    norm_mfcc_delta2 = (mfcc_delta2 - np.mean(mfcc_delta2, axis=1, keepdims=True)) / np.std(mfcc_delta2, axis=1, keepdims=True)\n",
        "\n",
        "    ac_feature = np.vstack((norm_mfcc, norm_mfcc_delta, norm_mfcc_delta2))\n",
        "    print(ac_feature.shape)\n",
        "\n",
        "    sub_seq_len = int(3.2 * sr / frame_shift)\n",
        "    sub_seq_step = int(0.8 * sr / frame_shift)\n",
        "\n",
        "    def extract_feature():\n",
        "        feature_len = ac_feature.shape[1]\n",
        "        sub_train_x = []\n",
        "        for i in range(0, feature_len-sub_seq_len, sub_seq_step):\n",
        "            sub_seq_x = np.transpose(ac_feature[:, i: i+sub_seq_len])\n",
        "            sub_train_x.append(sub_seq_x[np.newaxis, :, :])\n",
        "        return np.vstack(sub_train_x), feature_len\n",
        "\n",
        "    predict_x, feature_len = extract_feature()\n",
        "    print(predict_x.shape)\n",
        "\n",
        "    predict_y = model.predict(predict_x)\n",
        "    print(predict_y.shape)\n",
        "\n",
        "    score_acc = np.zeros((feature_len, 1))\n",
        "    score_cnt = np.ones((feature_len, 1))\n",
        "\n",
        "    for i in range(predict_y.shape[0]):\n",
        "        for j in range(predict_y.shape[1]):\n",
        "            index = i*sub_seq_step+j\n",
        "            score_acc[index] += predict_y[i, j, 0]\n",
        "            score_cnt[index] += 1\n",
        "\n",
        "    score_norm = score_acc / score_cnt\n",
        "\n",
        "    wStart = 0\n",
        "    wEnd = 200\n",
        "    wGrow = 200\n",
        "    delta = 25\n",
        "\n",
        "    store_cp = []\n",
        "    index = 0\n",
        "    while wEnd < feature_len:\n",
        "        score_seg = score_norm[wStart:wEnd]\n",
        "        max_v = np.max(score_seg)\n",
        "        max_index = np.argmax(score_seg)\n",
        "        index = index + 1\n",
        "        if max_v > 0.5:\n",
        "            temp = wStart + max_index\n",
        "            store_cp.append(temp)\n",
        "            wStart = wStart + max_index + 50\n",
        "            wEnd = wStart + wGrow\n",
        "        else:\n",
        "            wEnd = wEnd + wGrow\n",
        "\n",
        "    seg_point = np.array(store_cp)*frame_shift\n",
        "\n",
        "    plt.figure('speech segmentation plot')\n",
        "    plt.plot(np.arange(0, len(y)) / (float)(sr), y, \"b-\")\n",
        "\n",
        "    for i in range(len(seg_point)):\n",
        "        plt.vlines(seg_point[i] / (float)(sr), -1, 1, colors=\"c\", linestyles=\"dashed\")\n",
        "        plt.vlines(seg_point[i] / (float)(sr), -1, 1, colors=\"r\", linestyles=\"dashed\")\n",
        "    plt.xlabel(\"Time/s\")\n",
        "    plt.ylabel(\"Speech Amp\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return np.asarray(seg_point) / float(sr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AscFCvGGPsto",
        "outputId": "5e80d0a3-1336-44ee-ba2a-0ee317ed9607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 137, 256)         167936    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 137, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 137, 32)          8224      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 137, 32)          1056      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 137, 1)           33        \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 571,489\n",
            "Trainable params: 571,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Re-segmentation (Based on Combining VAD and Segementation Output)\n",
        "def group_intervals(a):\n",
        "    a = a.tolist()\n",
        "    ans = []\n",
        "\n",
        "    curr = None\n",
        "    for x in a:\n",
        "        # no previous interval under consideration\n",
        "        if curr == None:\n",
        "          curr = x\n",
        "        else:\n",
        "            # check if we can merge the intervals\n",
        "            if x[0]-curr[1] < 1:\n",
        "                curr[1] = x[1]\n",
        "            else:\n",
        "            # if we cannot merge, push the current element to ans\n",
        "                ans.append(curr)\n",
        "                curr = x\n",
        "\n",
        "        if curr is not None:\n",
        "            ans.append(curr)\n",
        "\n",
        "    d1 = np.asarray(ans)\n",
        "    d2 = np.unique(d1)\n",
        "    d3 = d2.reshape(int(len(d2)/2),2)\n",
        "    return d3\n",
        "    \n",
        "def spliting(seg,arr):\n",
        "  arr1 = arr.tolist()\n",
        "  temp = arr.copy()\n",
        "  \n",
        "  for i in range(len(seg)-1):\n",
        "    temp1 = float(seg[i])\n",
        "    # print(temp1)\n",
        "    #for j in range(len(arr)-1):\n",
        "    for j in range(len(arr)):\n",
        "      if ((temp1 > arr[j][0]) & (temp1 < arr[j][1])):\n",
        "        arr1[j].insert(-1,(temp1))\n",
        "\n",
        "  #for i in range(len(arr1-1)):\n",
        "  for i in range(len(arr1)):\n",
        "    size=len(arr1[i])\n",
        "    if size>=3:\n",
        "      arr1[i].pop(-2) if arr1[i][-1]-arr1[i][-2]<0.2 else True\n",
        "      \n",
        "  return arr1\n",
        "  \n",
        "def final_reseg(arr):\n",
        "  z=[]\n",
        "  for i in arr:\n",
        "    if len(i)==2:\n",
        "      z.append(i)\n",
        "    else:\n",
        "      temp = len(i)\n",
        "      for j in range(temp-1):\n",
        "        if j!=temp-1:\n",
        "          temp1 = [i[j],i[j+1]-0.01]\n",
        "          z.append(temp1)\n",
        "        elif j==temp-1:\n",
        "          temp1 = [i[j],i[j+1]]\n",
        "          z.append(temp1)\n",
        "  \n",
        "  return np.asarray(z)"
      ],
      "metadata": {
        "id": "SXH7Ts7GQAWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1JdDad7ndpk"
      },
      "source": [
        "#Embedding Extraction\n",
        "import torch\n",
        "import librosa\n",
        "from pyannote.core import Segment\n",
        "\n",
        "def embeddings_(audio_path,resegmented,range):\n",
        "  model_emb = torch.hub.load('pyannote/pyannote-audio', 'emb')\n",
        "  \n",
        "  embedding = model_emb({'audio': audio_path})\n",
        "  for window, emb in embedding:\n",
        "    assert isinstance(window, Segment)\n",
        "    assert isinstance(emb, np.ndarray)\n",
        "\n",
        "  y, sr = librosa.load(audio_path)\n",
        "  myDict={}\n",
        "  myDict['audio'] = audio_path\n",
        "  myDict['duration'] = len(y)/sr\n",
        "\n",
        "  data=[]\n",
        "  for i in resegmented:\n",
        "    excerpt = Segment(start=i[0], end=i[0]+range)\n",
        "    emb = model_emb.crop(myDict,excerpt)\n",
        "    data.append(emb.T)\n",
        "  data= np.asarray(data)\n",
        "  \n",
        "  return data.reshape(len(data),512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EjVUubjpB-w"
      },
      "source": [
        "#Generating Hypothesis\n",
        "from pyannote.core import Annotation, Segment\n",
        "def hypothesis_gen(hyp_df):\n",
        "  hyp_records = hyp_df.to_records(index=False)\n",
        "  hyp_rec = list(hyp_records)\n",
        "  hypothesis = Annotation()\n",
        "  for i in range(len(hyp_rec)-1):\n",
        "    hypothesis[Segment(hyp_rec[i][1], hyp_rec[i][2])] = hyp_rec[i][0]\n",
        "\n",
        "  return hypothesis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKLzU1mVpKyZ"
      },
      "source": [
        "#Diarization \n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "def diarization(audiofile):\n",
        "    voice = fxn(audiofile)\n",
        "    segmented = multi_segmentation(audiofile)\n",
        "    gp = group_intervals(voice)\n",
        "    splt = spliting(segmented,gp)\n",
        "    resegmented = final_reseg(splt)\n",
        "    embeddings = embeddings_(audiofile,resegmented,2)\n",
        "    speak_id , n_speakers = clustering(embeddings)\n",
        "    label_list = []\n",
        "    alpha = 'A'\n",
        "    for i in range(0, n_speakers): \n",
        "        label_list.append(alpha) \n",
        "        alpha = chr(ord(alpha) + 1) \n",
        "    lb = preprocessing.LabelEncoder()\n",
        "    label_hyp = lb.fit(label_list)\n",
        "    speaker_id = lb.inverse_transform(speak_id)\n",
        "    hyp_df = pd.DataFrame({'Speaker_id': speaker_id,'Offset': resegmented[:, 0], 'end': resegmented[:, 1]})\n",
        "    result_hypo = hypothesis_gen(hyp_df)  \n",
        "    return segmented, n_speakers, hyp_df, result_hypo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T17SeN1Hw__b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "fb595784-f1c8-493c-985b-dbb25357a585"
      },
      "source": [
        "#Give the path of audio file for Speaker Diarization (It should be Mono type.)\n",
        "segmented, n_clusters, hyp_df, result_hypo = diarization('/content/drive/My Drive/ProjectContent/Hindi_01.wav')\n",
        "print(n_clusters)\n",
        "print(hyp_df)\n",
        "result_hypo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(35, 78497)\n",
            "(2305, 137, 35)\n",
            "73/73 [==============================] - 25s 313ms/step\n",
            "(2305, 137, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pyannote_pyannote-audio_main\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-aecd3e930067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Give the path of audio file for Speaker Diarization (It should be Mono type.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msegmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_hypo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiarization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/ProjectContent/Hindi_01.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult_hypo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-6e75bae0c3c0>\u001b[0m in \u001b[0;36mdiarization\u001b[0;34m(audiofile)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msplt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspliting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmented\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mresegmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_reseg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresegmented\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mspeak_id\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_speakers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-99cb7f4acba1>\u001b[0m in \u001b[0;36membeddings_\u001b[0;34m(audio_path, resegmented, range)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0membeddings_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresegmented\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmodel_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pyannote/pyannote-audio'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m                                            verbose=verbose, skip_validation=skip_validation)\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_or_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_load_local\u001b[0;34m(hubconf_dir, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0mhubconf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhubconf_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m     \u001b[0mhub_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_import_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODULE_HUBCONF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhubconf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36m_import_module\u001b[0;34m(name, path)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/.cache/torch/hub/pyannote_pyannote-audio_main/hubconf.py'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMRwTnjJyu7A"
      },
      "source": [
        "#Evaluation (DER)\n",
        "def reference_gen(annotation_path):\n",
        "  df = pd.read_csv(annotation_path)\n",
        "  ref_df = df[df['filename'] == 'Hindi_01']\n",
        "  ref_df = ref_df.assign(end = ref_df.Offset + ref_df.Duration)\n",
        "  ref_df = ref_df[['Speaker_id','Offset','end']]\n",
        "  ref_records = ref_df.to_records(index=False)\n",
        "  ref_rec = list(ref_records)\n",
        "  reference = Annotation()\n",
        "  for i in range(len(ref_rec)-1):\n",
        "    reference[Segment(ref_rec[i][1], ref_rec[i][2])] = ref_rec[i][0]\n",
        "\n",
        "  return reference, ref_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooGFwg2cx96R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "33e94c12-9c01-415b-ee87-0755e4e631a5"
      },
      "source": [
        "#Give the path for Annotations File of Audio for calculating DER.\n",
        "reference, ref_df = reference_gen('/content/drive/My Drive/ProjectContent/hindi_annotations1.csv')\n",
        "#Visualization (Comparing Between Ground Truth and Hypothesis)\n",
        "reference"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyannote.core.annotation.Annotation at 0x7f26e9e57ee0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}