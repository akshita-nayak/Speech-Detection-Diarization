{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArKN7SwFByzS",
        "outputId": "e698ae62-1340-454a-d404-4110042d9297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "file_list = ['Hindi_01', 'Hindi_02', 'Hindi_03']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej0T1oatCzsw",
        "outputId": "485ada5b-bd36-4088-ad37-71c5fe994c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOWfG0Vs0KZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "c19ce815-8fb3-454b-dd44-2ad2a65e12db"
      },
      "source": [
        "#For Installing pyannote from github properly run this and the cell next to this.\n",
        "#Then Restart the runtime and again run both the cells to avoid further errors.\n",
        "!pip3 install typing-extensions==3.7.4.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting typing-extensions==3.7.4.1\n",
            "  Downloading typing_extensions-3.7.4.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.4.0\n",
            "    Uninstalling typing-extensions-4.4.0:\n",
            "      Successfully uninstalled typing-extensions-4.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydantic 1.10.2 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.1 which is incompatible.\n",
            "arviz 0.12.1 requires typing-extensions>=3.7.4.3, but you have typing-extensions 3.7.4.1 which is incompatible.\u001b[0m\n",
            "Successfully installed typing-extensions-3.7.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OJEXpvhKEJAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_feature(file_name):\n",
        "    file = \"/content/drive/My Drive/ProjectContent/\" + file_name + \".wav\"\n",
        "    frame_size = 2048\n",
        "    frame_shift = 512\n",
        "    y, sr = librosa.load(file)\n",
        "    #MFCC Extraction \n",
        "    mfccs = librosa.feature.mfcc(y, sr, n_mfcc=12, hop_length=frame_shift, n_fft=frame_size)\n",
        "    mfcc_delta = librosa.feature.delta(mfccs)\n",
        "    mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
        "\n",
        "    mfcc = mfccs[1:, ]\n",
        "    norm_mfcc = (mfcc - np.mean(mfcc, axis=1, keepdims=True)) / np.std(mfcc, axis=1, keepdims=True)\n",
        "    norm_mfcc_delta = (mfcc_delta - np.mean(mfcc_delta, axis=1, keepdims=True)) / np.std(mfcc_delta, axis=1, keepdims=True)\n",
        "    norm_mfcc_delta2= (mfcc_delta2 - np.mean(mfcc_delta2, axis=1, keepdims=True)) / np.std(mfcc_delta2, axis=1, keepdims=True)\n",
        "\n",
        "    ac_feature = np.vstack((norm_mfcc, norm_mfcc_delta, norm_mfcc_delta2))\n",
        "\n",
        "    #Loading Annotation File\n",
        "    ann = pd.read_csv('/content/drive/My Drive/ProjectContent/hindi_annotations1.csv')\n",
        "    ann['End_point'] = ann['Duration'] + ann['Offset']\n",
        "\n",
        "    change_point = []\n",
        "    for i in range(len(ann['End_point'])):\n",
        "        dur_1 = int((ann['End_point'][i]-0.075)*sr)  # left 50ms\n",
        "        dur_2 = int((ann['End_point'][i]+0.075)*sr)  # right 50ms\n",
        "        change_point.append((dur_1, dur_2))\n",
        "   \n",
        "    sub_seq_len = int(3.2*sr/frame_shift)\n",
        "    sub_seq_step= int(0.8*sr/frame_shift)\n",
        "\n",
        "    feature_len = ac_feature.shape[1]\n",
        "\n",
        "    def is_change_point(n):\n",
        "        flag = False\n",
        "        for x in change_point:\n",
        "            if n > x[0] and n < x[1]:\n",
        "                flag = True\n",
        "                break\n",
        "\n",
        "            if n+frame_size-1 > x[0] and n+frame_size-1 < x[1]:\n",
        "                flag = True\n",
        "                break\n",
        "        return flag\n",
        "\n",
        "    sub_train_x = []\n",
        "    sub_train_y = []\n",
        "    for i in range(0, feature_len-sub_seq_len, sub_seq_step):\n",
        "        sub_seq_x = np.transpose(ac_feature[:, i: i+sub_seq_len])\n",
        "        sub_train_x.append(sub_seq_x[np.newaxis, :, :])\n",
        "        tmp = []\n",
        "        for index in range(i, i+sub_seq_len):\n",
        "            if is_change_point(index*frame_shift):\n",
        "                tmp.append(1)\n",
        "            else:\n",
        "                tmp.append(0)\n",
        "        lab_y = np.array(tmp)\n",
        "        lab_y = np.reshape(lab_y, (1, sub_seq_len))\n",
        "        sub_train_y.append(lab_y)\n",
        "    return sub_train_x, sub_train_y\n",
        "   "
      ],
      "metadata": {
        "id": "vd8abcVNDQ__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    all_x = []\n",
        "    all_y = []\n",
        "    for audio_file in file_list:\n",
        "        new_train_x, new_train_y = extract_feature(audio_file)\n",
        "        new_train_x = np.vstack(new_train_x)\n",
        "        new_train_y = np.vstack(new_train_y)\n",
        "        print(new_train_x.shape)\n",
        "        print(new_train_y.shape)\n",
        "\n",
        "        all_x.append(new_train_x)\n",
        "        all_y.append(new_train_y)\n",
        "    print(len(all_x))\n",
        "    print(len(all_y))\n",
        "\n",
        "    all_x_stack = np.vstack(all_x)\n",
        "    all_y_stack = np.vstack(all_y)\n",
        "    print(all_x_stack.shape, all_y_stack.shape)\n",
        "    print('over')\n",
        "    return all_x_stack, all_y_stack"
      ],
      "metadata": {
        "id": "1SYE6iF5EM5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install install keras==2.3.1\n",
        "!pip3 install tensorflow==2.2\n",
        "from keras.legacy import interfaces\n",
        "from keras.optimizers import Optimizer\n",
        "from keras import backend as K\n",
        "#SNORM Optimizer\n",
        "class SMORMS3(Optimizer):\n",
        "\n",
        "    def __init__(self, learning_rate=0.001, epsilon=1e-16, decay=0.,\n",
        "                 **kwargs):\n",
        "        super(SMORMS3, self).__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.learning_rate = K.variable(learning_rate, name='learning_rate')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_decay = decay\n",
        "\n",
        "    @interfaces.legacy_get_updates_support\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        shapes = [K.shape(p) for p in params]\n",
        "        ms = [K.zeros(shape) for shape in shapes]\n",
        "        vs = [K.zeros(shape) for shape in shapes]\n",
        "        mems = [K.zeros(shape) for shape in shapes]\n",
        "        self.weights = [self.iterations] + ms + vs + mems\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        learning_rate = self.learning_rate\n",
        "        if self.initial_decay > 0:\n",
        "            learning_rate *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
        "                                                  K.dtype(self.decay))))\n",
        "\n",
        "\n",
        "        for p, g, m, v, mem in zip(params, grads, ms, vs, mems):\n",
        "\n",
        "            r = 1. / (1. + mem)\n",
        "            new_m = (1. - r) * m + r * g\n",
        "            new_v = (1. - r) * v + r * K.square(g)\n",
        "            denoise = K.square(new_m) / (new_v + self.epsilon)\n",
        "            new_p = p - g * K.minimum(learning_rate, denoise) / (K.sqrt(new_v) + self.epsilon)\n",
        "            new_mem = 1. + mem * (1. - denoise)\n",
        "\n",
        "            self.updates.append(K.update(m, new_m))\n",
        "            self.updates.append(K.update(v, new_v))\n",
        "            self.updates.append(K.update(mem, new_mem))\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'learning_rate': float(K.get_value(self.learning_rate)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'epsilon': self.epsilon}\n",
        "        base_config = super(SMORMS3, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl3BBl8yESIh",
        "outputId": "a69ef838-790a-42f0-ebcc-7ca3ffc21c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: keras==2.3.1 in /usr/local/lib/python3.8/dist-packages (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.2 in /usr/local/lib/python3.8/dist-packages (2.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (1.18.5)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (0.38.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (2.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (1.51.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (2.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (1.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.2) (3.19.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2) (3.2.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.core import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, TimeDistributed, Dropout\n",
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "def train_bilstm():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(TimeDistributed(Dense(32)))\n",
        "    model.add(TimeDistributed(Dense(32)))\n",
        "    model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "\n",
        "    model.build(input_shape=(None, 137, 35))\n",
        "\n",
        "    model.compile(loss=keras.losses.binary_crossentropy, optimizer=SMORMS3(), metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    all_x, all_y = load_dataset()\n",
        "    print(all_y.shape, np.sum(all_y))\n",
        "\n",
        "    subsample_all_x = []\n",
        "    subsample_all_y = []\n",
        "    for index in range(all_y.shape[0]):\n",
        "        class_positive = sum(all_y[index])\n",
        "        if class_positive > 5:\n",
        "            subsample_all_x.append(all_x[index][np.newaxis, :, :])\n",
        "            subsample_all_y.append(all_y[index])\n",
        "\n",
        "    all_x = np.vstack(subsample_all_x)\n",
        "    all_y = np.vstack(subsample_all_y)\n",
        "    print(all_y.shape, np.sum(all_y))\n",
        "\n",
        "    all_y = all_y[:, :, np.newaxis]\n",
        "\n",
        "    indices = np.random.permutation(all_x.shape[0])\n",
        "    all_x_random = all_x[indices]\n",
        "    all_y_random = all_y[indices]\n",
        "\n",
        "    datasize = all_x_random.shape[0]\n",
        "    train_size = int(datasize*0.97)\n",
        "    train_x = all_x_random[0:train_size]\n",
        "    valid_x = all_x_random[train_size:]\n",
        "\n",
        "    train_y = all_y_random[0:train_size]\n",
        "    valid_y = all_y_random[train_size:]\n",
        "    print('train over')\n",
        "\n",
        "    my = model.fit(x=train_x, y=train_y, batch_size=256, epochs=50,\n",
        "              validation_data=(valid_x, valid_y), shuffle=True)\n",
        "    model.save('/content/drive/My Drive/ProjectContent/model_hindi_2.h5')\n",
        "    def save_model(model, json_model_file, h5_model_file):\n",
        "        # serialize model to JSON\n",
        "        model_json = model.to_json()\n",
        "        with open(json_model_file, \"w\") as json_file:\n",
        "            json_file.write(model_json)\n",
        "        # serialize weights to HDF5\n",
        "        model.save_weights(h5_model_file)\n",
        "        print(\"Saved model to disk\")\n",
        "\n",
        "    model_name = 'speech_seg1'\n",
        "    json_model_file = '/content/drive/My Drive/ProjectContent/model_hindi_2'+'.json'\n",
        "    h5_model_file = '/content/drive/My Drive/ProjectContent/model_hindi_2'+'.h5'\n",
        "    save_model(model, json_model_file, h5_model_file)"
      ],
      "metadata": {
        "id": "-nQJafFsFu8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function to Train the Change detection Model based on Bi-LSTM\n",
        "train_bilstm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF4IVIkUGGMi",
        "outputId": "68840d73-281a-4e14-ff9a-cbc5b5b90e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_9 (Bidirection (None, 137, 256)          167936    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 137, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 137, 256)          394240    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 137, 256)          0         \n",
            "_________________________________________________________________\n",
            "time_distributed_13 (TimeDis (None, 137, 32)           8224      \n",
            "_________________________________________________________________\n",
            "time_distributed_14 (TimeDis (None, 137, 32)           1056      \n",
            "_________________________________________________________________\n",
            "time_distributed_15 (TimeDis (None, 137, 1)            33        \n",
            "=================================================================\n",
            "Total params: 571,489\n",
            "Trainable params: 571,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(2305, 137, 35)\n",
            "(2305, 137)\n",
            "(2256, 137, 35)\n",
            "(2256, 137)\n",
            "(696, 137, 35)\n",
            "(696, 137)\n",
            "3\n",
            "3\n",
            "(5257, 137, 35) (5257, 137)\n",
            "over\n",
            "(5257, 137) 11892\n",
            "(979, 137) 11643\n",
            "train over\n",
            "Train on 949 samples, validate on 30 samples\n",
            "Epoch 1/50\n",
            "949/949 [==============================] - 25s 26ms/step - loss: 0.6005 - accuracy: 0.7398 - val_loss: 0.5564 - val_accuracy: 0.8221\n",
            "Epoch 2/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5591 - accuracy: 0.8141 - val_loss: 0.5573 - val_accuracy: 0.8341\n",
            "Epoch 3/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5660 - accuracy: 0.7942 - val_loss: 0.5792 - val_accuracy: 0.8024\n",
            "Epoch 4/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5694 - accuracy: 0.7902 - val_loss: 0.5857 - val_accuracy: 0.7727\n",
            "Epoch 5/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5742 - accuracy: 0.7728 - val_loss: 0.5866 - val_accuracy: 0.7681\n",
            "Epoch 6/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5630 - accuracy: 0.8023 - val_loss: 0.5816 - val_accuracy: 0.8165\n",
            "Epoch 7/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5707 - accuracy: 0.7837 - val_loss: 0.5774 - val_accuracy: 0.8027\n",
            "Epoch 8/50\n",
            "949/949 [==============================] - 21s 22ms/step - loss: 0.5611 - accuracy: 0.8092 - val_loss: 0.5701 - val_accuracy: 0.8141\n",
            "Epoch 9/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5723 - accuracy: 0.7783 - val_loss: 0.5992 - val_accuracy: 0.7375\n",
            "Epoch 10/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5725 - accuracy: 0.7803 - val_loss: 0.5908 - val_accuracy: 0.7489\n",
            "Epoch 11/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5667 - accuracy: 0.7922 - val_loss: 0.5846 - val_accuracy: 0.7769\n",
            "Epoch 12/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5723 - accuracy: 0.7813 - val_loss: 0.5902 - val_accuracy: 0.7496\n",
            "Epoch 13/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5698 - accuracy: 0.7842 - val_loss: 0.5794 - val_accuracy: 0.7757\n",
            "Epoch 14/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5703 - accuracy: 0.7779 - val_loss: 0.5715 - val_accuracy: 0.8251\n",
            "Epoch 15/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5662 - accuracy: 0.7926 - val_loss: 0.5896 - val_accuracy: 0.7698\n",
            "Epoch 16/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5849 - accuracy: 0.7369 - val_loss: 0.6164 - val_accuracy: 0.6925\n",
            "Epoch 17/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5910 - accuracy: 0.7200 - val_loss: 0.6244 - val_accuracy: 0.6847\n",
            "Epoch 18/50\n",
            "949/949 [==============================] - 21s 22ms/step - loss: 0.6037 - accuracy: 0.6989 - val_loss: 0.6218 - val_accuracy: 0.6844\n",
            "Epoch 19/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6013 - accuracy: 0.7029 - val_loss: 0.5993 - val_accuracy: 0.7494\n",
            "Epoch 20/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5807 - accuracy: 0.7474 - val_loss: 0.6019 - val_accuracy: 0.7438\n",
            "Epoch 21/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5820 - accuracy: 0.7435 - val_loss: 0.5979 - val_accuracy: 0.7251\n",
            "Epoch 22/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5942 - accuracy: 0.7143 - val_loss: 0.6083 - val_accuracy: 0.7270\n",
            "Epoch 23/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5876 - accuracy: 0.7312 - val_loss: 0.6127 - val_accuracy: 0.6968\n",
            "Epoch 24/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5803 - accuracy: 0.7503 - val_loss: 0.5814 - val_accuracy: 0.7805\n",
            "Epoch 25/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5809 - accuracy: 0.7472 - val_loss: 0.6104 - val_accuracy: 0.6893\n",
            "Epoch 26/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5972 - accuracy: 0.7086 - val_loss: 0.6105 - val_accuracy: 0.7148\n",
            "Epoch 27/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5884 - accuracy: 0.7301 - val_loss: 0.5979 - val_accuracy: 0.7611\n",
            "Epoch 28/50\n",
            "949/949 [==============================] - 21s 22ms/step - loss: 0.5925 - accuracy: 0.7244 - val_loss: 0.6132 - val_accuracy: 0.7234\n",
            "Epoch 29/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6020 - accuracy: 0.7024 - val_loss: 0.6263 - val_accuracy: 0.6737\n",
            "Epoch 30/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6017 - accuracy: 0.7074 - val_loss: 0.6164 - val_accuracy: 0.7241\n",
            "Epoch 31/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6022 - accuracy: 0.7051 - val_loss: 0.6123 - val_accuracy: 0.7195\n",
            "Epoch 32/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5926 - accuracy: 0.7198 - val_loss: 0.6162 - val_accuracy: 0.6859\n",
            "Epoch 33/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6022 - accuracy: 0.7042 - val_loss: 0.6195 - val_accuracy: 0.7002\n",
            "Epoch 34/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5955 - accuracy: 0.7141 - val_loss: 0.6183 - val_accuracy: 0.6942\n",
            "Epoch 35/50\n",
            "949/949 [==============================] - 22s 23ms/step - loss: 0.6001 - accuracy: 0.7043 - val_loss: 0.6188 - val_accuracy: 0.6842\n",
            "Epoch 36/50\n",
            "949/949 [==============================] - 18s 18ms/step - loss: 0.6032 - accuracy: 0.7006 - val_loss: 0.6177 - val_accuracy: 0.6927\n",
            "Epoch 37/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5998 - accuracy: 0.7067 - val_loss: 0.6116 - val_accuracy: 0.7158\n",
            "Epoch 38/50\n",
            "949/949 [==============================] - 21s 22ms/step - loss: 0.5952 - accuracy: 0.7148 - val_loss: 0.6160 - val_accuracy: 0.7097\n",
            "Epoch 39/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6013 - accuracy: 0.7023 - val_loss: 0.6057 - val_accuracy: 0.7438\n",
            "Epoch 40/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6037 - accuracy: 0.6997 - val_loss: 0.6238 - val_accuracy: 0.6861\n",
            "Epoch 41/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5976 - accuracy: 0.7104 - val_loss: 0.6076 - val_accuracy: 0.7131\n",
            "Epoch 42/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5860 - accuracy: 0.7329 - val_loss: 0.5940 - val_accuracy: 0.7404\n",
            "Epoch 43/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5846 - accuracy: 0.7386 - val_loss: 0.6079 - val_accuracy: 0.7328\n",
            "Epoch 44/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5922 - accuracy: 0.7218 - val_loss: 0.6144 - val_accuracy: 0.7022\n",
            "Epoch 45/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6072 - accuracy: 0.6907 - val_loss: 0.6163 - val_accuracy: 0.6764\n",
            "Epoch 46/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.6036 - accuracy: 0.6980 - val_loss: 0.6219 - val_accuracy: 0.7107\n",
            "Epoch 47/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5921 - accuracy: 0.7225 - val_loss: 0.6135 - val_accuracy: 0.7054\n",
            "Epoch 48/50\n",
            "949/949 [==============================] - 20s 22ms/step - loss: 0.5968 - accuracy: 0.7137 - val_loss: 0.6070 - val_accuracy: 0.7326\n",
            "Epoch 49/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5906 - accuracy: 0.7237 - val_loss: 0.6115 - val_accuracy: 0.7178\n",
            "Epoch 50/50\n",
            "949/949 [==============================] - 17s 18ms/step - loss: 0.5928 - accuracy: 0.7165 - val_loss: 0.6039 - val_accuracy: 0.7423\n",
            "Saved model to disk\n"
          ]
        }
      ]
    }
  ]
}